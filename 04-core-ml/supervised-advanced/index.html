
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://evisp.github.io/ml-handbook/04-core-ml/supervised-advanced/">
      
      
        <link rel="prev" href="../supervised/">
      
      
        <link rel="next" href="../unsupervised/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.3">
    
    
      
        <title>Classification Advanced - Holberton ML Handbook</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#advanced-classification-ensemble-methods-and-support-vector-machines" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Holberton ML Handbook" class="md-header__button md-logo" aria-label="Holberton ML Handbook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Holberton ML Handbook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Classification Advanced
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/evisp/ml-handbook" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../01-tools/" class="md-tabs__link">
          
  
  
  Tools

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../02-math/" class="md-tabs__link">
          
  
  
  Math

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../03-data/" class="md-tabs__link">
          
  
  
  Data

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  Core ML

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../05-dl-fundamentals/" class="md-tabs__link">
          
  
  
  Deep Learning Fundamentals

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../06-dl-architectures/" class="md-tabs__link">
          
  
  
  Deep Learning Architectures

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Holberton ML Handbook" class="md-nav__button md-logo" aria-label="Holberton ML Handbook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Holberton ML Handbook
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/evisp/ml-handbook" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Tools
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Tools
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-tools/zero-day/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Zero day
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-tools/git-and-github/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Git & GitHub
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-tools/notebook-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Jupyter notebook setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-tools/vscode-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VS Code setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-tools/python-warm-up/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Python Warm Up
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Math
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Math
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-math/linear-algebra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linear algebra
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-math/numpy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NumPy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-math/calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Calculus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-math/probability-statistics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Probability & statistics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/data-foundations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Foundations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/pandas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pandas essentials
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/visualization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Visualization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/data-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Processing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/data-collection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data collection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/sql/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    SQL databases
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/mongo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NoSQL (MongoDB)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-data/mongo-install/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NoSQL (MongoDB install)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Core ML
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Core ML
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-categories/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML Categories
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lifecycle/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML Lifecycle
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../supervised/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Classification Advanced
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Classification Advanced
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#why-this-matters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why This Matters
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-example-production-spam-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running Example: Production Spam Detection
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-simple-methods-arent-enough" class="md-nav__link">
    <span class="md-ellipsis">
      
        When Simple Methods Aren't Enough
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector-machines" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support Vector Machines
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Support Vector Machines">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-kernel-trick" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Kernel Trick
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    <span class="md-ellipsis">
      
        Random Forest
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Random Forest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-it-works" class="md-nav__link">
    <span class="md-ellipsis">
      
        How It Works
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-importance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Feature Importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradient Boosting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Gradient Boosting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boosting-vs-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      
        Boosting vs Bagging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      
        XGBoost
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="XGBoost">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-makes-xgboost-special" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Makes XGBoost Special
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#core-differences-from-standard-gradient-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Differences from Standard Gradient Boosting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning Strategy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-importance_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Feature Importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comparing-advanced-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comparing Advanced Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Comparing Advanced Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Summary
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm Selection Guide
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quick-decision-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Decision Tree
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ensemble-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ensemble Stacking
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Ensemble Stacking">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#combining-multiple-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Combining Multiple Models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary and Next Steps
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unsupervised/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Unsupervised Learning Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Unsupervised Learning Clustering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dim_reduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Unsupervised Learning Dimensionality Reduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Deep Learning Fundamentals
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Deep Learning Fundamentals
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-dl-fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-dl-fundamentals/classification-nn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Classification Using Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-dl-fundamentals/optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-dl-fundamentals/error-analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Error Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-dl-fundamentals/regularization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Regularization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Deep Learning Architectures
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Deep Learning Architectures
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/convolutions-pooling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Convolutions and Pooling
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/cnns/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Convolutional Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/data-augmentation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Augmentation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/deep-cnns/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deep Convolutional Architectures
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/transfer-learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transfer Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../06-dl-architectures/object-detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Object Detection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#why-this-matters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why This Matters
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-example-production-spam-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running Example: Production Spam Detection
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-simple-methods-arent-enough" class="md-nav__link">
    <span class="md-ellipsis">
      
        When Simple Methods Aren't Enough
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector-machines" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support Vector Machines
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Support Vector Machines">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-kernel-trick" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Kernel Trick
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    <span class="md-ellipsis">
      
        Random Forest
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Random Forest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-it-works" class="md-nav__link">
    <span class="md-ellipsis">
      
        How It Works
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-importance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Feature Importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradient Boosting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Gradient Boosting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boosting-vs-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      
        Boosting vs Bagging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      
        XGBoost
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="XGBoost">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-makes-xgboost-special" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Makes XGBoost Special
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#core-differences-from-standard-gradient-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Differences from Standard Gradient Boosting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameter Tuning Strategy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-importance_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Feature Importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strengths-and-limitations_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Strengths and Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comparing-advanced-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comparing Advanced Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Comparing Advanced Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Summary
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm Selection Guide
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quick-decision-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Decision Tree
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ensemble-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ensemble Stacking
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Ensemble Stacking">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#combining-multiple-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Combining Multiple Models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary and Next Steps
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


  <nav class="md-path" aria-label="Navigation" >
    <ol class="md-path__list">
      
        
  
  
    <li class="md-path__item">
      <a href="../.." class="md-path__link">
        
  <span class="md-ellipsis">
    Home
  </span>

      </a>
    </li>
  

      
      
        
  
  
    
    
      <li class="md-path__item">
        <a href="../" class="md-path__link">
          
  <span class="md-ellipsis">
    Core ML
  </span>

        </a>
      </li>
    
  

      
    </ol>
  </nav>

              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="advanced-classification-ensemble-methods-and-support-vector-machines">Advanced Classification: Ensemble Methods and Support Vector Machines</h1>
<p>This tutorial introduces powerful classification techniques that solve problems where simple methods struggle. You'll learn <em>Support Vector Machines</em> for non-linear boundaries, <em>ensemble methods</em> that combine multiple models, and when to choose advanced approaches over simple baselines. Every concept connects to a real spam detection system handling complex feature interactions.</p>
<p><strong>Estimated time:</strong> 60 minutes</p>
<h2 id="why-this-matters">Why This Matters</h2>
<p><strong>Problem statement:</strong></p>
<blockquote>
<p>Simple classifiers work well on clean, linearly separable data. Real-world problems are messy, non-linear, and high-dimensional.</p>
</blockquote>
<p><strong>Real data challenges simple methods.</strong> A spam filter with just five features (link count, CAPSLOCK ratio, word count) works reasonably well with Logistic Regression. But production systems extract hundreds of features from email content, metadata, sender reputation, and historical patterns. These features interact in complex ways that linear boundaries cannot capture. A known sender becomes suspicious if they suddenly send many links. Simple classifiers miss these interactions.</p>
<p><strong>Practical benefits:</strong> Advanced methods deliver 5-15% accuracy improvements on hard problems, which translates to thousands fewer errors on large-scale systems. They handle noisy real-world data better through regularization and ensemble averaging. You can deploy them on datasets with hundreds or thousands of features without manual feature selection. The confidence scores they provide are better calibrated for decision-making under uncertainty.</p>
<p><strong>Professional context:</strong> Winning Kaggle solutions, production fraud detection systems, medical diagnosis tools, and credit scoring models all rely on these techniques. Random Forest and XGBoost dominate industry applications because they work well with minimal tuning. Understanding when a simple Logistic Regression baseline is sufficient versus when you need ensemble methods is a critical professional skill that separates junior from senior practitioners.</p>
<p><img alt="Simple Vs Ensemble" src="https://i.imgur.com/2Dx2WAT.png" /></p>
<h2 id="running-example-production-spam-detection">Running Example: Production Spam Detection</h2>
<p>Throughout this tutorial, we'll follow the evolution of our email spam filter from the simple classification tutorial. The original system used five hand-crafted features and achieved 85% F1-score with Logistic Regression. Production demands pushed us to improve accuracy to 92%+ to reduce the manual review workload that costs the company significant time and money.</p>
<p><strong>Enhanced dataset:</strong> The team now extracts 50+ features from each email including word frequencies for the top 30 spam-indicating terms, sender domain reputation scores, email metadata like send time and reply chain depth, text patterns such as repeated punctuation and ALL CAPS word count, attachment types and sizes, and historical sender behavior patterns. This rich feature set captures subtle spam signals but creates non-linear decision boundaries that simple methods cannot learn.</p>
<p><strong>Complex patterns emerge:</strong> High link count predicts spam unless the sender domain is a recognized corporate partner. Urgent language signals spam except when it comes from known finance or legal departments. Short emails with attachments are suspicious unless they match the sender's historical pattern. These feature interactions require advanced methods that can learn conditional rules.</p>
<p><strong>Business requirements:</strong> Precision must exceed 90% because blocking legitimate business emails damages customer relationships. Recall should reach 85% to keep inboxes clean without overwhelming manual reviewers. Training time matters less than prediction speed since the model runs millions of times daily. The solution must be explainable enough to debug false positives when customers complain.</p>
<h2 id="when-simple-methods-arent-enough">When Simple Methods Aren't Enough</h2>
<p>Simple classifiers have clear limitations that advanced methods address. Logistic Regression assumes a linear decision boundary, so it fails when spam occupies a circular region in feature space or when class membership depends on complex feature interactions. A single decision tree overfits easily, creating unstable models where small changes in training data produce completely different trees. K-Nearest Neighbors struggles with high-dimensional data where distances become meaningless and computation becomes prohibitively slow on large datasets.</p>
<p>The solution involves two main approaches. Kernel methods like Support Vector Machines transform features into higher-dimensional spaces where linear separation becomes possible without explicitly computing the transformation. Ensemble methods combine many weak models into one strong predictor, reducing both bias and variance through averaging or boosting. Both approaches trade increased computational cost and reduced interpretability for better predictive performance on complex problems.</p>
<h2 id="support-vector-machines">Support Vector Machines</h2>
<p><strong>Goal:</strong> Find the decision boundary that maximally separates classes while handling non-linear patterns through kernel transformations.</p>
<h3 id="the-core-idea">The Core Idea</h3>
<p>Support Vector Machines search for the widest possible margin between classes. Imagine a street separating spam from legitimate emails in feature space. The street's center line is the decision boundary, and its width is the margin. SVM finds the widest street where all spam emails are on one side and legitimate emails are on the other. The emails closest to the boundary, touching the street's edges, are called support vectors because they alone determine where the boundary sits. Points far from the boundary have no influence on the decision surface.</p>
<p>This <strong>maximum margin principle</strong> provides better generalization than methods that merely find any separating boundary. A wide margin means the model is confident about its decisions and less likely to misclassify new examples that fall near the boundary. The mathematical formulation seeks a hyperplane <span class="arithmatex">\(\mathbf{w} \cdot \mathbf{x} + b = 0\)</span> that maximizes the margin <span class="arithmatex">\(\frac{2}{||\mathbf{w}||}\)</span> while correctly classifying training points. Only the support vectors affect this optimization, making SVM memory-efficient on large datasets.</p>
<p><img alt="SVM" src="https://i.imgur.com/6PBrFik.png" /></p>
<h3 id="the-kernel-trick">The Kernel Trick</h3>
<p>Linear SVM works beautifully when classes are linearly separable, but real data rarely cooperates. Consider spam emails that cluster in a circular region within feature space, surrounded by legitimate emails. No straight line separates them. The kernel trick solves this by implicitly mapping data to a higher-dimensional space where linear separation becomes possible, without ever computing the transformation explicitly.</p>
<p>The <code>RBF (Radial Basis Function)</code> kernel is the most widely used transformation. It computes similarity between points using <span class="arithmatex">\(K(\mathbf{x}_i, \mathbf{x}_j) = e^{-\gamma ||\mathbf{x}_i - \mathbf{x}_j||^2}\)</span>, effectively creating infinite-dimensional feature space where a hyperplane can separate any pattern. The gamma parameter controls how far the influence of a single training example reaches. Low gamma means far reach and smooth decision boundaries. High gamma means nearby reach and complex, wiggly boundaries that can overfit.</p>
<p>For our spam example, linear boundaries fail because spam patterns involve combinations like "many links AND unknown sender" or "high CAPSLOCK OR urgent language from new contact." The RBF kernel learns these OR and AND combinations naturally by creating decision regions of arbitrary shape. A polynomial kernel <span class="arithmatex">\(K(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i \cdot \mathbf{x}_j + c)^d\)</span> captures polynomial feature interactions up to degree d, useful when you know the relationship has that specific form.</p>
<h3 id="implementation">Implementation</h3>
<p>Training an SVM requires scaled features because the algorithm computes distances between points. Features with large magnitudes dominate the distance calculation, so we must standardize all features to comparable scales before training.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="c1"># Prepare data</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">X</span> <span class="o">=</span> <span class="n">emails</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>  <span class="c1"># 50+ features</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="n">y</span> <span class="o">=</span> <span class="n">emails</span><span class="p">[</span><span class="s1">&#39;is_spam&#39;</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="c1"># Split</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="p">)</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="c1"># Scale features (critical for SVM!)</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="c1"># Train SVM with RBF kernel</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="n">model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>                    <span class="c1"># Regularization strength</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span>            <span class="c1"># Kernel coefficient</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span>  <span class="c1"># Handle imbalanced classes</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="p">)</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="c1"># Predict</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>  <span class="c1"># Distance from boundary</span>
</span></code></pre></div>
<p>The <code>C</code> parameter controls the trade-off between margin width and training accuracy. Small <code>C</code> values (0.1) allow more misclassifications but create wider, simpler margins that generalize better. Large <code>C</code> values (100) insist on classifying training points correctly, creating narrow margins that may overfit. Start with <code>C=1</code> and adjust based on cross-validation performance.</p>
<p>The <code>gamma</code> parameter for RBF kernels determines decision boundary complexity. Small <code>gamma</code> (0.001) creates smooth, simple boundaries that may underfit. Large <code>gamma</code> (10) creates complex, wiggly boundaries that can memorize training data. The <code>'scale'</code> setting uses <span class="arithmatex">\(1 / (n_{features} \times X.var())\)</span> as a reasonable default that adapts to your data.</p>
<h3 id="hyperparameter-tuning">Hyperparameter Tuning</h3>
<p>Finding optimal <code>C</code> and <code>gamma</code> requires systematic search over a grid of values. We use <strong>cross-validation</strong> to estimate performance for each combination and select the pair that maximizes our target metric.</p>
<blockquote>
<p>Cross-validation is a technique that tests how well a model performs on unseen data by splitting the dataset into multiple subsets called folds. The model trains on some folds and tests on the remaining fold, repeating this process multiple times with different combinations so each fold serves as the test set once. The results from all iterations are averaged to provide a reliable estimate of the model's true performance and ability to generalize to new data.</p>
</blockquote>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="c1"># Define parameter grid</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>    <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;scale&#39;</span><span class="p">]</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="p">}</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="c1"># Grid search with cross-validation</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    <span class="n">param_grid</span><span class="p">,</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a><span class="p">)</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best parameters: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best F1-score: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a><span class="c1"># Use best model</span>
</span><span id="__span-1-25"><a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a><span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
</span></code></pre></div>
<p>This search tests 20 combinations (4 C values  5 gamma values) using 5-fold cross-validation, running 100 total training jobs. Parallel execution with <code>n_jobs=-1</code>uses all CPU cores to speed up the search. For larger parameter spaces, use <code>RandomizedSearchCV</code> to sample a subset of combinations rather than exhaustively testing all.</p>
<h3 id="strengths-and-limitations">Strengths and Limitations</h3>
<p>SVM excels with non-linear patterns where kernel transformations create separable feature spaces. It works well in high-dimensional spaces and remains effective even when the number of features exceeds the number of samples. Memory efficiency comes from storing only support vectors rather than all training data. The maximum margin principle provides strong generalization when classes have clear separation.</p>
<p>However, SVM trains slowly on large datasets because the optimization problem scales poorly beyond 50,000 samples. Feature scaling is mandatory, adding a preprocessing step. The many hyperparameters (kernel choice, C, gamma) require careful tuning through cross-validation. Standard SVM does not output probability estimates, only decision function values, though calibration methods can convert these. The resulting model is a black box with little interpretability compared to decision trees.</p>
<blockquote>
<p>Use SVM when you have non-linear patterns that simpler methods miss, high-dimensional feature spaces like text or images, medium-sized datasets under 50,000 samples, and expectations of clear class separation. </p>
</blockquote>
<p>Avoid SVM for very large datasets where training time becomes prohibitive, when you need probability estimates and interpretability, or when simple linear methods already work well.</p>
<h2 id="random-forest">Random Forest</h2>
<p><strong>Goal:</strong> Build many diverse decision trees and combine their predictions through voting to create a robust, accurate classifier.</p>
<h3 id="the-core-idea_1">The Core Idea</h3>
<p>A single decision tree overfits easily and produces unstable predictions where small changes in training data create completely different trees. Random Forest solves both problems by growing hundreds of trees on random subsets of data and features, then averaging their predictions. This ensemble approach reduces overfitting because errors from individual trees cancel out when averaged. It increases stability because no single tree dominates the final prediction.</p>
<p>Each tree in the forest trains on a bootstrap sample, which randomly selects samples with replacement from the training set. This means each tree sees about 63% of the data, with some samples appearing multiple times and others not at all. At each split point, the tree considers only a random subset of features rather than all features. For classification, the typical subset size is the square root of the total number of features. These two sources of randomness, sample and feature randomness, ensure trees learn different patterns and make diverse predictions.</p>
<p>The final classification uses majority voting. Each tree votes for spam or legitimate, and the class receiving the most votes wins. The proportion of trees voting for the winning class serves as a confidence score. If 85 of 100 trees predict spam, the model is 85% confident. This confidence helps flag borderline cases for manual review.</p>
<p><img alt="Random Forest" src="https://i.imgur.com/Wy317f0.png" /></p>
<h3 id="how-it-works">How It Works</h3>
<p>For our spam detection with 50 features and 8,000 training emails, Random Forest might build 100 trees as follows. Each tree receives a bootstrap sample of roughly 5,000 emails (some duplicates, some missing). At each decision node, the tree considers only 7 random features (50  7) to find the best split. The tree grows fully without pruning, potentially memorizing its particular bootstrap sample.</p>
<p>Tree 1 might focus on link count and sender domain patterns because those features appeared in its random subsets. Tree 2 emphasizes text features and send time. Tree 3 captures CAPSLOCK and urgent language interactions. The diversity means each tree is an expert on different aspects of spam detection. When a new email arrives, all 100 trees vote based on their specialized knowledge, and the majority decision combines these diverse perspectives into a robust prediction.</p>
<p>This diversity-through-randomness principle is why Random Forest works so well in practice. Individual trees overfit their bootstrap samples, but their errors are uncorrelated. Some trees mistakenly classify a legitimate email as spam, but other trees correctly classify it. The majority vote cancels out these random errors, leaving only the signal that all trees agree on.</p>
<h3 id="implementation_1">Implementation</h3>
<p>Random Forest requires no feature scaling and works directly with the original features, making implementation simpler than SVM.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="c1"># Train Random Forest (no scaling needed!)</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>          <span class="c1"># Number of trees</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>              <span class="c1"># Maximum tree depth</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>      <span class="c1"># Minimum samples to split</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>       <span class="c1"># Minimum samples per leaf</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>    <span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span>       <span class="c1"># K features per split</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>    <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span>   <span class="c1"># Handle class imbalance</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>                  <span class="c1"># Parallel training</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a><span class="p">)</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a><span class="c1"># Predict</span>
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a><span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a><span class="c1"># Evaluate</span>
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> 
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>                           <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Legitimate&#39;</span><span class="p">,</span> <span class="s1">&#39;Spam&#39;</span><span class="p">]))</span>
</span></code></pre></div>
<p>The <code>n_estimators</code> parameter sets the number of trees. More trees generally improve performance but with diminishing returns beyond <code>200-300</code> trees and increased memory and prediction time. Start with <code>100</code> trees and increase if cross-validation shows continued improvement. Training parallelizes across trees with <code>n_jobs=-1</code>, providing near-linear speedup on multi-core machines.</p>
<p>Limiting tree depth through max_depth prevents individual trees from overfitting their bootstrap samples. Unlimited depth allows trees to grow until all leaves are pure, which overfits dramatically. Setting max_depth between 10 and 30 usually works well, creating trees deep enough to capture patterns but shallow enough to generalize. The min_samples_split and min_samples_leaf parameters provide alternative controls by preventing splits that create tiny nodes.</p>
<h3 id="feature-importance">Feature Importance</h3>
<p>Random Forest provides feature importance scores that reveal which features most influence predictions. Importance is computed by measuring how much each feature decreases impurity (Gini or entropy) when used for splitting, averaged across all trees and all nodes where that feature appears.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="c1"># Extract feature importances</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="n">importances</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="n">feature_names</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="c1"># Create importance dataframe</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">importances</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a><span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a><span class="c1"># Display top 15 features</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a><span class="nb">print</span><span class="p">(</span><span class="n">importance_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a><span class="c1"># Visualize</span>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a><span class="n">top_features</span> <span class="o">=</span> <span class="n">importance_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a><span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span> <span class="n">top_features</span><span class="p">[</span><span class="s1">&#39;importance&#39;</span><span class="p">])</span>
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Importance Score&#39;</span><span class="p">)</span>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Top 15 Features for Spam Detection&#39;</span><span class="p">)</span>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></div>
<p>Sample output might show <code>sender_known (0.18)</code>, <code>domain_reputation (0.14)</code>, <code>num_links (0.12)</code>, and <code>capslock_ratio (0.09)</code> as the top features. This reveals that sender reputation matters most, followed by content characteristics. Features with near-zero importance can be removed to simplify the model and speed up training without sacrificing accuracy.</p>
<p>These importance scores guide feature engineering efforts. If text-based features dominate, invest in better natural language processing. If metadata features rank low despite your intuition, investigate whether they contain useful signal or are just noise. Feature importance also helps explain predictions to stakeholders by highlighting which attributes most influence the spam versus legitimate decision.</p>
<h3 id="hyperparameter-tuning_1">Hyperparameter Tuning</h3>
<p>While Random Forest works well with default settings, tuning can improve performance by several percentage points. Focus on the parameters that most affect model complexity and diversity.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="c1"># Define parameter distributions</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:,[</span><span class="mi">11</span><span class="p">]</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>    <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">,</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">,</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>    <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="p">}</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="c1"># Randomized search (faster than grid search)</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a><span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>    <span class="n">param_dist</span><span class="p">,</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>    <span class="n">n_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>          <span class="c1"># Try 30 random combinations</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a><span class="p">)</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a><span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best parameters: </span><span class="si">{</span><span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best F1-score: </span><span class="si">{</span><span class="n">random_search</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a><span class="c1"># Use best model</span>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a><span class="n">best_rf</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_estimator_</span>
</span></code></pre></div>
<p>Randomized search samples 30 random combinations from the parameter space, which is more efficient than grid search when you have many parameters. This completes much faster while often finding equally good solutions. Increase n_iter if you have computational budget and want more thorough exploration.</p>
<h3 id="strengths-and-limitations_1">Strengths and Limitations</h3>
<p>Random Forest reduces overfitting compared to single decision trees through ensemble averaging. It handles non-linear patterns naturally without kernel tricks. No feature scaling is required, simplifying preprocessing. Feature importance scores provide interpretability despite the ensemble. The algorithm handles missing values internally and works well out-of-the-box with minimal tuning. Parallel training across trees makes it fast on multi-core systems.</p>
<p>Limitations include reduced interpretability compared to a single tree since you cannot visualize 100 trees easily. Prediction is slower than simple models because every tree must evaluate the input. Memory requirements grow with the number of trees and their depth. While less prone to overfitting than single trees, Random Forest can still overfit with unlimited depth and too many trees. Text and very high-dimensional data may require feature reduction before Random Forest works well.</p>
<p>Use Random Forest as your default choice for tabular classification problems. It works well without extensive tuning, handles feature interactions naturally, and provides feature importance for interpretation. It is particularly good when you have hundreds of features with unknown interactions, imbalanced classes that need weighting, and limited time for hyperparameter tuning. Avoid it when you need a simple, interpretable model for stakeholders or when prediction latency is critical.</p>
<h2 id="gradient-boosting">Gradient Boosting</h2>
<p><strong>Goal:</strong> Build trees sequentially where each new tree corrects errors made by previous trees, creating a strong predictor from many weak learners.</p>
<h3 id="the-core-idea_2">The Core Idea</h3>
<p>Gradient Boosting takes a fundamentally different approach than Random Forest. Instead of building trees independently and voting, it builds trees sequentially where each tree learns to predict the residual errors of all previous trees. Start with a simple prediction like the majority class. Build a small tree that predicts where that initial model makes errors. Add that tree's predictions to the initial model. Build another tree to predict the remaining errors. Repeat this process hundreds of times, each iteration reducing the residual errors.</p>
<p>The name "gradient" comes from using gradient descent to minimize a loss function, similar to training neural networks. Each new tree moves predictions in the direction that most reduces the loss. The name "boosting" refers to boosting the performance of weak learners, typically shallow trees with only a few splits. These weak learners are easy to train and generalize well individually, but ensemble them sequentially and they create powerful predictors.</p>
<p>This sequential error-correction mechanism makes Gradient Boosting particularly effective on hard problems. Early trees learn the obvious patterns that simple methods would catch. Later trees focus on edge cases and subtle patterns that only appear in the residuals. By the 100th tree, the model has refined its predictions through a hundred rounds of error correction, achieving accuracy that no single model could match.</p>
<p><img alt="Gradient Boosting" src="https://i.imgur.com/0mLb6Jf.png" /></p>
<h3 id="boosting-vs-bagging">Boosting vs Bagging</h3>
<p>Random Forest uses bagging, which builds independent models and averages their predictions. Each tree in a Random Forest trains on a bootstrap sample and has no knowledge of other trees. The diversity comes from random sampling. This parallel structure allows fast training but limits how much trees can learn from each other.</p>
<p>Gradient Boosting uses boosting, which builds models sequentially where each model knows about all previous models. Tree 1 learns the main patterns. Tree 2 looks at what Tree 1 got wrong and tries to fix those errors. Tree 3 looks at what Trees 1 and 2 together still get wrong. This sequential structure means later trees become experts on hard cases that early trees miss. However, training must be sequential, making it slower than Random Forest.</p>
<p>For our spam example, Tree 1 might learn "unknown sender with many links is spam" and catch 60% of spam emails. Tree 2 examines the 40% of spam Tree 1 missed and learns "urgent language without links is also spam." Tree 3 focuses on false positives, learning "known corporate senders with many links are legitimate." Each tree specializes in patterns the ensemble currently handles poorly.</p>
<h3 id="implementation_2">Implementation</h3>
<p>Gradient Boosting requires careful hyperparameter tuning to avoid overfitting since sequential error correction can eventually memorize training data.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="c1"># Train Gradient Boosting</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>         <span class="c1"># Number of boosting stages</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>        <span class="c1"># Shrinkage parameter</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>              <span class="c1"># Keep trees shallow (weak learners)</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>            <span class="c1"># Use 80% of data per tree</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>    <span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span>      <span class="c1"># Feature sampling</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="p">)</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="c1"># Predict</span>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a><span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></code></pre></div>
<p>The learning_rate controls how much each tree contributes to the final prediction. Small learning rates like 0.01 require more trees but often generalize better. Large learning rates like 0.3 converge faster but may overfit. A common strategy uses learning_rate=0.1 with n_estimators=100 as a starting point, then adjusts the pair since their product determines total model capacity.</p>
<p>Keeping trees shallow through max_depth=3 is critical for boosting. Deep trees memorize data, while shallow trees learn simple patterns that generalize. Boosting combines many shallow trees to build complexity gradually. Trees with 3 levels (max_depth=3) can encode 8 rules, enough to capture meaningful patterns without overfitting.</p>
<p>The subsample parameter adds randomness by training each tree on a random 80% subset of data. This stochastic gradient boosting reduces overfitting and speeds up training. Combined with max_features for random feature selection, it brings some of Random Forest's diversity benefits to boosting.</p>
<h3 id="hyperparameter-tuning_2">Hyperparameter Tuning</h3>
<p>Gradient Boosting has many hyperparameters that interact in complex ways. Effective tuning proceeds in stages, fixing some parameters while searching over others.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="c1"># Stage 1: Find optimal learning_rate and n_estimators</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="n">param_grid_1</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">11</span><span class="p">]</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="p">}</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="n">grid_1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>    <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>    <span class="n">param_grid_1</span><span class="p">,</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a><span class="p">)</span>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a><span class="n">grid_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a><span class="n">best_lr</span> <span class="o">=</span> <span class="n">grid_1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span>
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a><span class="n">best_n</span> <span class="o">=</span> <span class="n">grid_1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">]</span>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a><span class="c1"># Stage 2: Tune tree structure with best lr and n</span>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a><span class="n">param_grid_2</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">,</span>
</span><span id="__span-6-23"><a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>    <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">,</span>
</span><span id="__span-6-24"><a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>    <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> 
</span><span id="__span-6-25"><a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a><span class="p">}</span>
</span><span id="__span-6-26"><a id="__codelineno-6-26" name="__codelineno-6-26" href="#__codelineno-6-26"></a>
</span><span id="__span-6-27"><a id="__codelineno-6-27" name="__codelineno-6-27" href="#__codelineno-6-27"></a><span class="n">grid_2</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
</span><span id="__span-6-28"><a id="__codelineno-6-28" name="__codelineno-6-28" href="#__codelineno-6-28"></a>    <span class="n">GradientBoostingClassifier</span><span class="p">(</span>
</span><span id="__span-6-29"><a id="__codelineno-6-29" name="__codelineno-6-29" href="#__codelineno-6-29"></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="n">best_lr</span><span class="p">,</span>
</span><span id="__span-6-30"><a id="__codelineno-6-30" name="__codelineno-6-30" href="#__codelineno-6-30"></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="n">best_n</span><span class="p">,</span>
</span><span id="__span-6-31"><a id="__codelineno-6-31" name="__codelineno-6-31" href="#__codelineno-6-31"></a>        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
</span><span id="__span-6-32"><a id="__codelineno-6-32" name="__codelineno-6-32" href="#__codelineno-6-32"></a>    <span class="p">),</span>
</span><span id="__span-6-33"><a id="__codelineno-6-33" name="__codelineno-6-33" href="#__codelineno-6-33"></a>    <span class="n">param_grid_2</span><span class="p">,</span>
</span><span id="__span-6-34"><a id="__codelineno-6-34" name="__codelineno-6-34" href="#__codelineno-6-34"></a>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-6-35"><a id="__codelineno-6-35" name="__codelineno-6-35" href="#__codelineno-6-35"></a>    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
</span><span id="__span-6-36"><a id="__codelineno-6-36" name="__codelineno-6-36" href="#__codelineno-6-36"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
</span><span id="__span-6-37"><a id="__codelineno-6-37" name="__codelineno-6-37" href="#__codelineno-6-37"></a><span class="p">)</span>
</span><span id="__span-6-38"><a id="__codelineno-6-38" name="__codelineno-6-38" href="#__codelineno-6-38"></a><span class="n">grid_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-6-39"><a id="__codelineno-6-39" name="__codelineno-6-39" href="#__codelineno-6-39"></a>
</span><span id="__span-6-40"><a id="__codelineno-6-40" name="__codelineno-6-40" href="#__codelineno-6-40"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best parameters: </span><span class="si">{</span><span class="n">grid_2</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-6-41"><a id="__codelineno-6-41" name="__codelineno-6-41" href="#__codelineno-6-41"></a><span class="n">final_model</span> <span class="o">=</span> <span class="n">grid_2</span><span class="o">.</span><span class="n">best_estimator_</span>
</span></code></pre></div>
<p>This two-stage approach reduces the search space by first finding the right learning rate and number of trees, then optimizing tree structure. Searching all parameters simultaneously would require testing hundreds of combinations, which is computationally expensive.</p>
<h3 id="strengths-and-limitations_2">Strengths and Limitations</h3>
<p>Gradient Boosting often achieves the best performance on tabular data because sequential error correction captures subtle patterns. It handles mixed feature types, missing values, and feature interactions well. Built-in feature importance helps interpret which attributes matter most. The algorithm is less prone to overfitting than Random Forest when properly tuned, especially with small learning rates and early stopping.</p>
<p>However, training is slow because trees must be built sequentially rather than in parallel. The many interacting hyperparameters require careful tuning through cross-validation. It is easy to overfit without proper validation monitoring and early stopping. The model is less interpretable than Random Forest because predictions involve summing hundreds of tree predictions rather than simple voting. Gradient Boosting is more sensitive to hyperparameter choices than Random Forest, meaning default settings often underperform.</p>
<p>Use Gradient Boosting when you need maximum accuracy and have time for tuning, work with tabular data that has complex patterns, can afford slower training in exchange for better predictions, and plan to deploy in production where prediction speed matters more than training speed. Avoid it when you need quick results without tuning, have very large datasets where sequential training is prohibitive, or prioritize model interpretability for stakeholder communication.</p>
<h2 id="xgboost">XGBoost</h2>
<p><strong>Goal:</strong> Highly optimized implementation of gradient boosting with built-in regularization, parallel tree construction, and advanced features for production deployment.</p>
<h3 id="what-makes-xgboost-special">What Makes XGBoost Special</h3>
<p>XGBoost (eXtreme Gradient Boosting) revolutionized machine learning competitions and production systems by making gradient boosting faster, more accurate, and easier to use. It introduces several innovations beyond standard gradient boosting. Parallel tree construction speeds up training by 10-100 compared to scikit-learn's implementation. Built-in L1 and L2 regularization prevents overfitting more effectively. Automatic handling of missing values eliminates preprocessing steps. Cross-validation and early stopping integrate into the training process. Custom loss functions enable optimization for business-specific metrics.</p>
<p>These improvements transformed gradient boosting from an academic technique into an industry standard. Kaggle competitions are dominated by XGBoost solutions. Tech companies deploy it at scale for ranking, recommendation, and fraud detection. The library continues active development with GPU support, distributed training, and integration with modern ML platforms.</p>
<p><img alt="XGBoost" src="https://i.imgur.com/B65kveo.png" /></p>
<h3 id="core-differences-from-standard-gradient-boosting">Core Differences from Standard Gradient Boosting</h3>
<p>Standard Gradient Boosting builds trees one at a time in strict sequence. XGBoost parallelizes tree construction by evaluating all possible splits simultaneously across CPU cores, dramatically reducing training time. It adds regularization terms to the loss function that penalize complex trees, preventing the overfitting that plagues standard implementations. The algorithm handles missing values by learning the optimal default direction for each split rather than requiring imputation.</p>
<p>The software engineering is exceptional. XGBoost implements cache-aware algorithms that minimize memory access patterns. It uses sparsity-aware split finding that efficiently handles sparse features common in text and categorical data. Out-of-core computation allows training on datasets larger than memory. These optimizations make XGBoost practical for production systems processing millions of examples.</p>
<h3 id="implementation_3">Implementation</h3>
<p>XGBoost offers two APIs. The native API provides maximum control and performance. The scikit-learn compatible API enables drop-in replacement for existing pipelines.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xgb</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">classification_report</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="c1"># Prepare data in DMatrix format (optimized for XGBoost)</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="c1"># Set parameters</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>    <span class="s1">&#39;objective&#39;</span><span class="p">:</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>     <span class="c1"># Binary classification</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a>    <span class="s1">&#39;eval_metric&#39;</span><span class="p">:</span> <span class="s1">&#39;logloss&#39;</span><span class="p">,</span>           <span class="c1"># Loss to optimize</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>                     <span class="c1"># Tree depth</span>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>               <span class="c1"># Eta (step size)</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>    <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>                   <span class="c1"># Row sampling per tree</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>    <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>            <span class="c1"># Column sampling per tree</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>    <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>                   <span class="c1"># L1 regularization</span>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>                  <span class="c1"># L2 regularization</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>    <span class="s1">&#39;scale_pos_weight&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>              <span class="c1"># Handle imbalance (neg/pos ratio)</span>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>    <span class="s1">&#39;seed&#39;</span><span class="p">:</span> <span class="mi">42</span>
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a><span class="p">}</span>
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a>
</span><span id="__span-7-22"><a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a><span class="c1"># Train with early stopping</span>
</span><span id="__span-7-23"><a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a><span class="n">evals</span> <span class="o">=</span> <span class="p">[(</span><span class="n">dtrain</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="p">(</span><span class="n">dtest</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">)]</span>
</span><span id="__span-7-24"><a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a><span class="n">model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
</span><span id="__span-7-25"><a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a>    <span class="n">params</span><span class="p">,</span>
</span><span id="__span-7-26"><a id="__codelineno-7-26" name="__codelineno-7-26" href="#__codelineno-7-26"></a>    <span class="n">dtrain</span><span class="p">,</span>
</span><span id="__span-7-27"><a id="__codelineno-7-27" name="__codelineno-7-27" href="#__codelineno-7-27"></a>    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>               <span class="c1"># Maximum trees</span>
</span><span id="__span-7-28"><a id="__codelineno-7-28" name="__codelineno-7-28" href="#__codelineno-7-28"></a>    <span class="n">evals</span><span class="o">=</span><span class="n">evals</span><span class="p">,</span>
</span><span id="__span-7-29"><a id="__codelineno-7-29" name="__codelineno-7-29" href="#__codelineno-7-29"></a>    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>           <span class="c1"># Stop if no improvement</span>
</span><span id="__span-7-30"><a id="__codelineno-7-30" name="__codelineno-7-30" href="#__codelineno-7-30"></a>    <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">50</span>                     <span class="c1"># Print every 50 rounds</span>
</span><span id="__span-7-31"><a id="__codelineno-7-31" name="__codelineno-7-31" href="#__codelineno-7-31"></a><span class="p">)</span>
</span><span id="__span-7-32"><a id="__codelineno-7-32" name="__codelineno-7-32" href="#__codelineno-7-32"></a>
</span><span id="__span-7-33"><a id="__codelineno-7-33" name="__codelineno-7-33" href="#__codelineno-7-33"></a><span class="c1"># Predict</span>
</span><span id="__span-7-34"><a id="__codelineno-7-34" name="__codelineno-7-34" href="#__codelineno-7-34"></a><span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">)</span>
</span><span id="__span-7-35"><a id="__codelineno-7-35" name="__codelineno-7-35" href="#__codelineno-7-35"></a><span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred_proba</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="__span-7-36"><a id="__codelineno-7-36" name="__codelineno-7-36" href="#__codelineno-7-36"></a>
</span><span id="__span-7-37"><a id="__codelineno-7-37" name="__codelineno-7-37" href="#__codelineno-7-37"></a><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Legitimate&#39;</span><span class="p">,</span> <span class="s1">&#39;Spam&#39;</span><span class="p">]))</span>
</span></code></pre></div>
<p>The DMatrix format stores data in XGBoost's optimized internal representation, reducing memory and speeding up training. The params dictionary controls all aspects of training. The evals list specifies datasets to monitor during training, enabling early stopping when validation performance plateaus. Training prints progress every 50 rounds, showing how loss decreases.</p>
<p>The scikit-learn API offers familiar syntax for quick experiments:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBClassifier</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="c1"># Train with sklearn API</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>    <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>    <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>    <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>    <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span>
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a><span class="p">)</span>
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>    <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)],</span>
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
</span><span id="__span-8-23"><a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a><span class="p">)</span>
</span><span id="__span-8-24"><a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a>
</span><span id="__span-8-25"><a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-8-26"><a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a><span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></code></pre></div>
<p>Both APIs produce equivalent models. Use the native API for maximum performance and access to all features. Use the scikit-learn API for compatibility with existing pipelines and tools like GridSearchCV.</p>
<h3 id="key-hyperparameters">Key Hyperparameters</h3>
<p>The <code>max_depth</code> parameter controls tree complexity. Deeper trees capture more interactions but overfit more easily. Start with 6 and decrease to 3-4 if overfitting or increase to 8-10 if underfitting. Unlimited depth almost always overfits, so always set a limit.</p>
<p>The <code>learning_rate</code> (also called eta) determines how much each tree contributes. Smaller learning rates like 0.01 require more trees but generalize better. Larger rates like 0.3 converge faster but may overfit. The standard approach uses 0.1 with 100-300 trees, then decreases learning rate and increases trees if you have more computational budget.</p>
<p>Sampling parameters add randomness to reduce overfitting. The <code>subsample</code> parameter trains each tree on a random fraction of rows, typically 0.6-0.9. The <code>colsample_bytree</code> parameter samples columns once per tree, while <code>colsample_bylevel</code> samples columns at each tree level. These create diversity similar to Random Forest while maintaining boosting's error-correction advantage.</p>
<p>Regularization parameters penalize complex models. The <code>reg_alpha</code> parameter adds L1 regularization that encourages sparsity, pushing some feature weights to zero. The <code>reg_lambda</code> parameter adds L2 regularization that shrinks all weights toward zero. Increase these when overfitting. Typical values range from 0 (no regularization) to 10 (strong regularization).</p>
<p>The <code>scale_pos_weight</code> parameter handles class imbalance by weighting positive examples more heavily. Set it to the ratio of negative to positive examples. For 5% spam in your dataset, use <code>scale_pos_weight=19</code> to weight spam 19 more than legitimate emails. This helps the model focus on learning the minority class.</p>
<h3 id="hyperparameter-tuning-strategy">Hyperparameter Tuning Strategy</h3>
<p>Tuning XGBoost effectively requires an organized approach because the parameter space is large and parameters interact.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">randint</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="c1"># Define parameter distributions</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.29</span><span class="p">),</span>  <span class="c1"># 0.01 to 0.3</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>    <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>        <span class="c1"># 0.6 to 0.9</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>    <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>    <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>    <span class="s1">&#39;scale_pos_weight&#39;</span><span class="p">:</span> <span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a><span class="p">}</span>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a><span class="c1"># Randomized search</span>
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a><span class="n">search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a>    <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>    <span class="n">param_dist</span><span class="p">,</span>
</span><span id="__span-9-20"><a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>    <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>                <span class="c1"># Try 50 random combinations</span>
</span><span id="__span-9-21"><a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-9-22"><a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
</span><span id="__span-9-23"><a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
</span><span id="__span-9-24"><a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-9-25"><a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a>    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
</span><span id="__span-9-26"><a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a><span class="p">)</span>
</span><span id="__span-9-27"><a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a>
</span><span id="__span-9-28"><a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a><span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-9-29"><a id="__codelineno-9-29" name="__codelineno-9-29" href="#__codelineno-9-29"></a>
</span><span id="__span-9-30"><a id="__codelineno-9-30" name="__codelineno-9-30" href="#__codelineno-9-30"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best parameters: </span><span class="si">{</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-9-31"><a id="__codelineno-9-31" name="__codelineno-9-31" href="#__codelineno-9-31"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best cross-val F1: </span><span class="si">{</span><span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-9-32"><a id="__codelineno-9-32" name="__codelineno-9-32" href="#__codelineno-9-32"></a>
</span><span id="__span-9-33"><a id="__codelineno-9-33" name="__codelineno-9-33" href="#__codelineno-9-33"></a><span class="c1"># Evaluate on test set</span>
</span><span id="__span-9-34"><a id="__codelineno-9-34" name="__codelineno-9-34" href="#__codelineno-9-34"></a><span class="n">best_model</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span>
</span><span id="__span-9-35"><a id="__codelineno-9-35" name="__codelineno-9-35" href="#__codelineno-9-35"></a><span class="n">test_predictions</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-9-36"><a id="__codelineno-9-36" name="__codelineno-9-36" href="#__codelineno-9-36"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test F1: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">test_predictions</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>This randomized search samples 50 combinations from continuous and discrete distributions, running 250 total training jobs with 5-fold cross-validation. Continuous parameters use uniform distributions while discrete parameters use randint. This approach finds good hyperparameters much faster than exhaustive grid search.</p>
<p>After randomized search finds a promising region, you can run a finer grid search around those values. For example, if randomized search finds max_depth=5 works well, search [4, 5, 6] more carefully. This two-stage coarse-then-fine approach balances exploration and exploitation.</p>
<h3 id="feature-importance_1">Feature Importance</h3>
<p>XGBoost provides multiple feature importance metrics that reveal different aspects of how features contribute to predictions.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="c1"># Get importance by weight (number of times feature used)</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="n">importance_weight</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="c1"># Get importance by gain (average gain when feature used)</span>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="n">importance_gain</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;gain&#39;</span><span class="p">)</span>
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a><span class="c1"># Get importance by cover (average coverage of samples)</span>
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a><span class="n">importance_cover</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;cover&#39;</span><span class="p">)</span>
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a><span class="c1"># Visualize gain-based importance</span>
</span><span id="__span-10-13"><a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a><span class="n">xgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;gain&#39;</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</span><span id="__span-10-14"><a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Top 15 Features by Average Gain&#39;</span><span class="p">)</span>
</span><span id="__span-10-15"><a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</span><span id="__span-10-16"><a id="__codelineno-10-16" name="__codelineno-10-16" href="#__codelineno-10-16"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span id="__span-10-17"><a id="__codelineno-10-17" name="__codelineno-10-17" href="#__codelineno-10-17"></a>
</span><span id="__span-10-18"><a id="__codelineno-10-18" name="__codelineno-10-18" href="#__codelineno-10-18"></a><span class="c1"># Convert to DataFrame for analysis</span>
</span><span id="__span-10-19"><a id="__codelineno-10-19" name="__codelineno-10-19" href="#__codelineno-10-19"></a><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
</span><span id="__span-10-20"><a id="__codelineno-10-20" name="__codelineno-10-20" href="#__codelineno-10-20"></a><span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
</span><span id="__span-10-21"><a id="__codelineno-10-21" name="__codelineno-10-21" href="#__codelineno-10-21"></a>    <span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">importance_gain</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span>
</span><span id="__span-10-22"><a id="__codelineno-10-22" name="__codelineno-10-22" href="#__codelineno-10-22"></a>    <span class="s1">&#39;gain&#39;</span><span class="p">:</span> <span class="n">importance_gain</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span><span id="__span-10-23"><a id="__codelineno-10-23" name="__codelineno-10-23" href="#__codelineno-10-23"></a><span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;gain&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-10-24"><a id="__codelineno-10-24" name="__codelineno-10-24" href="#__codelineno-10-24"></a>
</span><span id="__span-10-25"><a id="__codelineno-10-25" name="__codelineno-10-25" href="#__codelineno-10-25"></a><span class="nb">print</span><span class="p">(</span><span class="n">importance_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
</span></code></pre></div>
<p>Weight importance counts how many times a feature appears in split conditions across all trees. This metric identifies frequently used features but doesn't distinguish between important and trivial splits. Gain importance measures the average improvement in loss when the feature is used for splitting. This better reflects which features actually improve predictions. Cover importance counts the average number of samples affected by splits on the feature, revealing features that influence many predictions even if they don't always improve the loss much.</p>
<h3 id="strengths-and-limitations_3">Strengths and Limitations</h3>
<p>XGBoost often achieves the best accuracy on structured data through sophisticated regularization and optimization. Fast training and prediction enable deployment in production systems processing millions of requests. Built-in handling of missing values eliminates preprocessing. Integrated cross-validation and early stopping prevent overfitting. </p>
<p>Limitations include the complexity of tuning many interacting hyperparameters. Installation can be tricky on some systems due to compiler requirements. The model is less interpretable than Random Forest despite feature importance scores. Default hyperparameters may underperform compared to properly tuned settings. XGBoost is overkill for small, simple datasets where Logistic Regression works fine.</p>
<p>Use XGBoost when you need maximum accuracy on structured data, have datasets with more than 10,000 samples, need production-ready performance with fast predictions, work with imbalanced classes, and have time for hyperparameter tuning. It is the default choice for Kaggle competitions and many production ML systems. Avoid it for very small datasets under 1,000 samples where simpler methods work better, when you need maximum interpretability for stakeholders, or when default hyperparameters must work well without tuning.</p>
<h2 id="comparing-advanced-methods">Comparing Advanced Methods</h2>
<h3 id="performance-summary">Performance Summary</h3>
<p>Real-world performance on our 50-feature spam detection problem shows clear patterns. Logistic Regression as the baseline achieves 82% F1-score in 1 second training time, establishing that the problem benefits from more sophisticated methods. A single Decision Tree reaches only 78% F1 in 2 seconds, overfitting badly despite regularization. Random Forest improves to 89% F1 in 15 seconds, showing the power of ensemble methods. SVM with RBF kernel achieves 88% F1 but requires 45 seconds due to the dataset size. Standard Gradient Boosting reaches 91% F1 in 60 seconds of sequential training. XGBoost wins with 92% F1 in only 20 seconds thanks to parallelization and optimization.</p>
<p>These results demonstrate that advanced methods deliver meaningful improvements. The 10 percentage point gain from Logistic Regression to XGBoost means thousands fewer errors on a production system processing millions of emails. However, the diminishing returns from Random Forest (89%) to XGBoost (92%) suggest that further improvement requires substantial additional effort through better features or ensemble stacking.</p>
<h3 id="algorithm-selection-guide">Algorithm Selection Guide</h3>
<p>Choose SVM when you have non-linear patterns that kernel transformations can separate, high-dimensional sparse data like text features, medium-sized datasets under 50,000 samples where training time is acceptable, and clear class separation in feature space. SVM excels in applications like text classification, bioinformatics with sequence data, and image classification with engineered features.</p>
<p>Choose Random Forest as your default starting point for tabular data. It works well without extensive tuning, provides feature importance for interpretation, handles hundreds of features naturally, and trains quickly through parallelization. Use it when you need robust performance quickly, have mixed feature types, want to understand feature contributions, or lack time for hyperparameter tuning.</p>
<p>Choose Gradient Boosting when you need the best possible accuracy, have time for careful hyperparameter tuning, work with structured tabular data, and can afford slower training for better predictions. It is particularly effective when Random Forest underperforms, you have carefully curated features, and production latency is more important than training time.</p>
<p>Choose XGBoost for production systems requiring maximum accuracy with fast predictions, large datasets over 10,000 samples, imbalanced classes common in fraud detection and rare event prediction, and scenarios where regularization prevents overfitting. It dominates Kaggle competitions and production deployments at major tech companies.</p>
<h3 id="quick-decision-tree">Quick Decision Tree</h3>
<p>Start with a simple Logistic Regression baseline to establish performance without complex methods. If accuracy is sufficient and the problem is simple, deploy it. If baseline accuracy is insufficient, try Random Forest next because it requires minimal tuning and works well across diverse problems. If Random Forest provides good accuracy, deploy it unless you need better performance. If you need higher accuracy and have computational budget, tune XGBoost hyperparameters through cross-validation. If XGBoost still doesn't meet requirements, investigate better features, ensemble methods, or deep learning.</p>
<p>This progression builds complexity only when simpler methods fail, avoiding the trap of using advanced techniques unnecessarily. Many production systems run on Random Forest or simple XGBoost configurations because the extra accuracy from perfect tuning doesn't justify the engineering cost.</p>
<h2 id="ensemble-stacking">Ensemble Stacking</h2>
<h3 id="combining-multiple-models">Combining Multiple Models</h3>
<p>Ensemble stacking combines predictions from diverse models to achieve better performance than any single model. The key insight is that different algorithms make different types of errors. Random Forest might excel with noisy features while XGBoost captures subtle interactions. SVM handles high-dimensional patterns that tree methods miss. Averaging their predictions often yields better results than picking the best individual model.</p>
<p>Simple voting averages predictions or probabilities across models. Train a Random Forest, XGBoost, and SVM independently. For each test example, get predictions from all three. Use majority voting for hard predictions or average probabilities for soft voting. This approach works best when models are diverse and roughly equally accurate.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">VotingClassifier</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="c1"># Define base models</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="n">xgb_model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a><span class="c1"># Create voting ensemble</span>
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a><span class="n">voting_clf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>    <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>        <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">rf</span><span class="p">),</span>
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>        <span class="p">(</span><span class="s1">&#39;xgb&#39;</span><span class="p">,</span> <span class="n">xgb_model</span><span class="p">),</span>
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>        <span class="p">(</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">svm</span><span class="p">)</span>
</span><span id="__span-11-14"><a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>    <span class="p">],</span>
</span><span id="__span-11-15"><a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span>  <span class="c1"># Average probabilities</span>
</span><span id="__span-11-16"><a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a><span class="p">)</span>
</span><span id="__span-11-17"><a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>
</span><span id="__span-11-18"><a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a><span class="n">voting_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-11-19"><a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a><span class="n">predictions</span> <span class="o">=</span> <span class="n">voting_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></code></pre></div>
<p>Stacking uses a meta-learner trained on base model predictions. Train multiple base models on the training data. Use cross-validation to generate predictions on the training set without leakage. Train a meta-model like Logistic Regression on these predictions. For test examples, get predictions from base models and feed them to the meta-model.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">StackingClassifier</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="c1"># Define base models</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="n">base_models</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>    <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>    <span class="p">(</span><span class="s1">&#39;xgb&#39;</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>    <span class="p">(</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="p">]</span>
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a><span class="c1"># Create stacking ensemble</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a><span class="n">stacking_clf</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span>
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>    <span class="n">estimators</span><span class="o">=</span><span class="n">base_models</span><span class="p">,</span>
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>    <span class="n">final_estimator</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(),</span>
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>  <span class="c1"># Cross-validation for meta-features</span>
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a><span class="p">)</span>
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a><span class="n">stacking_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a><span class="n">predictions</span> <span class="o">=</span> <span class="n">stacking_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></code></pre></div>
<p>Stacking typically gains 1-3 percentage points over the best base model. Use it when you have computational resources for training multiple models, need maximum possible accuracy, and work on competitions or critical applications where small gains matter. Avoid it when interpretability matters, production latency constraints are tight, or maintaining multiple models creates operational complexity.</p>
<h2 id="best-practices">Best Practices</h2>
<p><strong>Always start with a simple baseline</strong> before trying advanced methods. Train Logistic Regression first to establish performance without complexity. This baseline tells you whether the problem truly needs sophisticated techniques. If Logistic Regression achieves 95% accuracy, XGBoost might reach 97%, but that 2% gain may not justify the added complexity.</p>
<p><strong>Use cross-validation</strong> instead of single train-test splits for reliable performance estimates. Five-fold cross-validation runs five training jobs and averages results, providing confidence intervals around your metrics. This prevents overfitting to a particular train-test split during hyperparameter tuning.</p>
<p><strong>Monitor training versus validation performance</strong> to detect overfitting. If training accuracy is 99% but validation is 85%, your model memorizes rather than generalizes. Increase regularization, reduce model complexity, or collect more data. For tree-based methods, plot training and validation learning curves to see where overfitting begins.</p>
<p><strong>Feature scaling matters</strong> for distance-based methods like SVM but not for tree-based methods. Always scale features for SVM using StandardScaler. Random Forest, Gradient Boosting, and XGBoost work directly with original features, simplifying preprocessing.</p>
<p><strong>Invest time in hyperparameter tuning</strong> for production systems where small accuracy gains have large business impact. Use RandomizedSearchCV to explore the parameter space efficiently, then GridSearchCV to refine promising regions. Track all experiments in a spreadsheet or MLflow to avoid repeating failed configurations.</p>
<p><strong>Balance accuracy against latency</strong> in production systems. XGBoost with 500 trees might be 1% more accurate than 100 trees but 5 slower at prediction time. If your system processes millions of requests, that latency multiplies to unacceptable delays. Profile prediction time and choose the fastest model that meets accuracy requirements.</p>
<h2 id="summary-and-next-steps">Summary and Next Steps</h2>
<p><strong>Key accomplishments:</strong> You have learned when simple classifiers are insufficient and advanced methods provide value. You mastered Support Vector Machines for non-linear boundaries through kernel transformations. You understood Random Forest as an ensemble of diverse trees that vote on predictions. You explored Gradient Boosting's sequential error correction and XGBoost's optimized implementation. You compared methods to choose appropriate algorithms for different scenarios. You practiced hyperparameter tuning through cross-validation.</p>
<p><img alt="Happy Analyst" src="https://i.imgur.com/Q1yFv4a.png" /></p>
<p><strong>Critical insights:</strong> No single algorithm dominates all problems, so match method to problem characteristics. Start simple with Logistic Regression, escalate to Random Forest, then XGBoost only when needed. Proper hyperparameter tuning improves performance by 5-15%, making it worthwhile for production systems. Ensemble methods reduce both bias and variance through diversity and averaging. XGBoost's engineering excellence makes it the industry standard for structured data.</p>
<p><strong>Connections:</strong> These advanced methods build on foundations from the simple classification tutorial, requiring the same evaluation metrics and handling imbalanced classes with the same techniques. The data preprocessing tutorial is critical because feature engineering often improves performance more than switching algorithms. These same algorithms work for regression by changing the objective function, as covered in the regression tutorial.</p>
<p><strong>What's next:</strong> Learn model deployment patterns for serving predictions in production systems at scale. Explore AutoML frameworks that automate hyperparameter tuning and model selection. Study deep learning for images, text, and sequences where neural networks outperform tree-based methods. Investigate model interpretability techniques like SHAP values for explaining individual predictions.</p>
<p><strong>External resources:</strong> The XGBoost documentation at xgboost.readthedocs.io provides comprehensive coverage of parameters and techniques. Scikit-learn's ensemble methods guide at scikit-learn.org covers Random Forest and Gradient Boosting implementation details. Kaggle competitions at kaggle.com offer practice on real problems where these techniques shine.</p>
<blockquote>
<p>Remember that advanced methods provide 5-15% improvement over simple baselines. Make sure you need that improvement before adding complexity. Random Forest and XGBoost should be your defaults for tabular data, but always compare against Logistic Regression to know whether the improvement justifies the cost.</p>
</blockquote>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.path", "navigation.top", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>